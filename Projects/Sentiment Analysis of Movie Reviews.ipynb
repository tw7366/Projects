{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\"\n",
      " 'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'\n",
      " 'I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I\\'d laughed at one of Woody\\'s comedies in years (dare I say a decade?). While I\\'ve never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.']\n"
     ]
    }
   ],
   "source": [
    "reviews_df = pd.read_csv(r'C:\\Users\\taewoo\\Desktop\\Datasets\\IMDB Dataset.csv')\n",
    "reviews = np.array(reviews_df['review'])\n",
    "sentiment = np.array(reviews_df['sentiment'])\n",
    "print(reviews[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"one of the other reviewers has mentioned that after watching just 1 oz episode you'll be hooked. they are right as this is exactly what happened with me. the first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go. trust me this is not a show for the faint hearted or timid. this show pulls no punches with regards to drugs sex or violence. its is hardcore in the classic use of the word. it is called oz as that is the nickname given to the oswald maximum security state penitentary. it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda. em city is home to many..aryans muslims gangstas latinos christians italians irish and more....so scuffles death stares dodgy dealings and shady agreements are never far away. i would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. forget pretty pictures painted for mainstream audiences forget charm forget romance...oz doesn't mess around. the first episode i ever saw struck me as so nasty it was surreal i couldn't say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence. not just violence but injustice crooked guards who'll be sold out for a nickel inmates who'll kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\"\n",
      " \"a wonderful little production. the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece. the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams' diary entries not only is it well worth the watching but it is a terrificly written and performed piece. a masterful production about one of the great master's of comedy and his life. the realism really comes home with the little things the fantasy of the guard which rather than use the traditional 'dream' techniques remains solid then disappears. it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwell's murals decorating every surface are terribly well done.\"\n",
      " \"i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air conditioned theater and watching a lighthearted comedy. the plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer. while some may be disappointed when they realize this is not match point 2 risk addiction i thought it was proof that woody allen is still fully in control of the style many of us have grown to love. this was the most i'd laughed at one of woody's comedies in years dare i say a decade. while i've never been impressed with scarlet johanson in this she managed to tone down her sexy image and jumped right into a average but spirited young woman. this may not be the crown jewel of his career but it was wittier than devil wears prada and more interesting than superman a great comedy to go see with friends.\"]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_review(review_list):\n",
    "    \"\"\"\n",
    "    param: a list of string\n",
    "    return: a list of string\n",
    "    preprocess reviews by changing all alphabets to lowercase, removing punctuations, and cleaning html leftover code\n",
    "    \"\"\"\n",
    "    for i, review in enumerate(review_list):\n",
    "        review = review.replace('<br /><br />', ' ')\n",
    "        review = review.lower()\n",
    "        review = re.sub(r\"[^A-Za-z0-9'. ]+\", '', review)\n",
    "        review = review.replace('  ', ' ')\n",
    "        review_list[i] = review\n",
    "    return review_list\n",
    "\n",
    "preprocessed_reviews = preprocess_review(reviews)\n",
    "print(preprocessed_reviews[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1708, 6)           948912    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               896       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 951,889\n",
      "Trainable params: 951,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# to divide train & test sets\n",
    "test_sample_size = int(0.1*len(preprocessed_reviews))  # 10% of data as the validation set\n",
    "\n",
    "# for sentiment\n",
    "sentiment = [1 if x=='positive' else 0 for x in sentiment]\n",
    "\n",
    "# separate data to train & test sets\n",
    "X_test, X_train = (np.array(preprocessed_reviews[:test_sample_size]), \n",
    "                   np.array(preprocessed_reviews[test_sample_size:])\n",
    ")\n",
    "\n",
    "y_test, y_train = (np.array(sentiment[:test_sample_size]), \n",
    "                   np.array(sentiment[test_sample_size:])\n",
    ")\n",
    "\n",
    "tokenizer = Tokenizer(oov_token='<OOV>')  # for the unknown words\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "vocab_count = len(tokenizer.word_index) + 1  # +1 is for padding\n",
    "\n",
    "# create padded sequences\n",
    "training_sequences = tokenizer.texts_to_sequences(X_train)  # tokenizer.word_index to see indexes\n",
    "training_padded = pad_sequences(training_sequences, padding='post')  # pad sequences with 0s \n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(X_test)  # tokenizer.word_index to see indexes\n",
    "testing_padded = pad_sequences(testing_sequences, padding='post')  # pad sequences with 0s \n",
    "\n",
    "input_length = len(testing_padded[0])  # length of all sequences\n",
    "\n",
    "\n",
    "# build a model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(input_dim=vocab_count,\n",
    "                                 output_dim=6,\n",
    "                                 input_length=input_length))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())  # find the average of vectors to get sentiment\n",
    "model.add(keras.layers.Dense(128, activation='relu'))  # hidden layer\n",
    "model.add(keras.layers.Dense(16, activation='relu'))  # hidden layer\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # output layer\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive', 'positive', 'positive', 'negative', 'positive'] [1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:5], y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(sentiment[:test_sample_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1708) for input Tensor(\"embedding_input:0\", shape=(None, 1708), dtype=float32), but it was called on an input with incompatible shape (None, 2459).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1708) for input Tensor(\"embedding_input:0\", shape=(None, 1708), dtype=float32), but it was called on an input with incompatible shape (None, 2459).\n",
      "88/88 [==============================] - 8s 92ms/step - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6932 - val_accuracy: 0.4936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22b8da05460>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_padded, y_train, epochs=1, batch_size=512,\n",
    "          validation_data=(testing_padded, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has predicted 2532 wrong\n"
     ]
    }
   ],
   "source": [
    "index_list = []\n",
    "predictions = model.predict(testing_padded)\n",
    "predictions = ['negative' if x <= 0.5 else 'positive' for x in predictions]\n",
    "y_test = ['negative' if x <= 0.5 else 'positive' for x in y_test]\n",
    "for i, (prediction, truth) in enumerate(zip(predictions, y_test)):\n",
    "    if prediction != truth:\n",
    "        index_list.append(i)\n",
    "\n",
    "print(f'The model has predicted {len(index_list)} wrong')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of the faulty predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basically there's a family where a little boy jake thinks there's a zombie in his closet his parents are fighting all the time. this movie is slower than a soap opera... and suddenly jake decides to become rambo and kill the zombie. ok first of all when you're going to make a film you must decide if its a thriller or a drama as a drama the movie is watchable. parents are divorcing arguing like in real life. and then we have jake with his closet which totally ruins all the film i expected to see a boogeyman similar movie and instead i watched a drama with some meaningless thriller spots. 3 out of 10 just for the well playing parents descent dialogs. as for the shots with jake just ignore them.\n",
      "Prediction: positive\n",
      "Sentiment: negative\n",
      "============================\n",
      "this show was an amazing fresh innovative idea in the 70's when it first aired. the first 7 or 8 years were brilliant but things dropped off after that. by 1990 the show was not really funny anymore and it's continued its decline further to the complete waste of time it is today. it's truly disgraceful how far this show has fallen. the writing is painfully bad the performances are almost as bad if not for the mildly entertaining respite of the guesthosts this show probably wouldn't still be on the air. i find it so hard to believe that the same creator that handselected the original cast also chose the band of hacks that followed. how can one recognize such brilliance and then see fit to replace it with such mediocrity i felt i must give 2 stars out of respect for the original cast that made this show such a huge success. as it is now the show is just awful. i can't believe it's still on the air.\n",
      "Prediction: positive\n",
      "Sentiment: negative\n",
      "============================\n",
      "encouraged by the positive comments about this film on here i was looking forward to watching this film. bad mistake. i've seen 950 films and this is truly one of the worst of them it's awful in almost every way editing pacing storyline 'acting' soundtrack the film's only song a lame country tune is played no less than four times. the film looks cheap and nasty and is boring in the extreme. rarely have i been so happy to see the end credits of a film. the only thing that prevents me giving this a 1score is harvey keitel while this is far from his best performance he at least seems to be making a bit of an effort. one for keitel obsessives only.\n",
      "Prediction: positive\n",
      "Sentiment: negative\n",
      "============================\n",
      "phil the alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines. at first it was very odd and pretty funny but as the movie progressed i didn't find the jokes or oddness funny anymore. its a low budget film thats never a problem in itself there were some pretty interesting characters but eventually i just lost interest. i imagine this film would appeal to a stoner who is currently partaking. for something similar but better try brother from another planet\n",
      "Prediction: positive\n",
      "Sentiment: negative\n",
      "============================\n",
      "i saw this movie when i was about 12 when it came out. i recall the scariest scene was the big bird eating men dangling helplessly from parachutes right out of the air. the horror. the horror. as a young kid going to these cheesy b films on saturday afternoons i still was tired of the formula for these monster type movies that usually included the hero a beautiful woman who might be the daughter of a professor and a happy resolution when the monster died in the end. i didn't care much for the romantic angle as a 12 year old and the predictable plots. i love them now for the unintentional humor. but about a year or so later i saw psycho when it came out and i loved that the star janet leigh was bumped off early in the film. i sat up and took notice at that point. since screenwriters are making up the story make it up to be as scary as possible and not from a wellworn formula. there are no rules.\n",
      "Prediction: positive\n",
      "Sentiment: negative\n",
      "============================\n",
      "so im not a big fan of boll's work but then again not many are. i enjoyed his movie postal maybe im the only one. boll apparently bought the rights to use far cry long ago even before the game itself was even finsished. people who have enjoyed killing mercs and infiltrating secret research labs located on a tropical island should be warned that this is not far cry... this is something mr boll have schemed together along with his legion of schmucks.. feeling loneley on the set mr boll invites three of his countrymen to play with. these players go by the names of til schweiger udo kier and ralf moeller. three names that actually have made them selfs pretty big in the movie biz. so the tale goes like this jack carver played by til schweiger yes carver is german all hail the bratwurst eating dudes however i find that tils acting in this movie is pretty badass.. people have complained about how he's not really staying true to the whole carver agenda but we only saw carver in a first person perspective so we don't really know what he looked like when he was kicking a.. however the storyline in this film is beyond demented. we see the evil mad scientist dr. krieger played by udo kier making geneticallymutatedsoldiers or gms as they are called. performing his topsecret research on an island that reminds me of spoiler vancouver for some reason. thats right no palm trees here. instead we got some nice rich lumberjackwoods. we haven't even gone far before i started to cry mehehe i cannot go on any more.. if you wanna stay true to bolls shenanigans then go and see this movie you will not be disappointed it delivers the true boll experience meaning most of it will suck. there are some things worth mentioning that would imply that boll did a good work on some areas of the film such as some nice boat and fighting scenes. until the whole cromedalbino gms squad enters the scene and everything just makes me laugh.. the movie far cry reeks of scheisse that's poop for you simpletons from a far if you wanna take a wiff go ahead.. btw carver gets a very annoying sidekick who makes you wanna shoot him the first three minutes he's on screen.\n",
      "Prediction: positive\n",
      "Sentiment: negative\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(index_list):\n",
    "    if i <= 5:\n",
    "        print(X_test[item])\n",
    "        print(f'Prediction: {predictions[item]}')\n",
    "        print(f'Sentiment: {y_test[item]}')\n",
    "        print('============================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model made good assumptions for most of them, but it got easily confused by words like 'good', 'bad', 'well', etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1708, 6)           948912    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 16)                1472      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 950,401\n",
      "Trainable params: 950,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "new_model = keras.models.Sequential()\n",
    "new_model.add(keras.layers.Embedding(input_dim=vocab_count,\n",
    "                                 output_dim=6,\n",
    "                                 input_length=input_length)\n",
    ")\n",
    "new_model.add(keras.layers.LSTM(16))\n",
    "new_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "new_model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(new_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'int\\'>\"})'}), (<class 'list'> containing values of types {\"<class 'numpy.int32'>\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3edcbab70dab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m new_model.fit(training_sequences, y_train, epochs=5, batch_size=256,\n\u001b[0m\u001b[0;32m      4\u001b[0m               validation_data=(testing_sequences, y_test))\n",
      "\u001b[1;32mc:\\users\\taewoo\\pycharmprojects\\data-analysis-practice\\venv\\interpreter\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\taewoo\\pycharmprojects\\data-analysis-practice\\venv\\interpreter\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\taewoo\\pycharmprojects\\data-analysis-practice\\venv\\interpreter\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m     self._adapter = adapter_cls(\n\u001b[0;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\taewoo\\pycharmprojects\\data-analysis-practice\\venv\\interpreter\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    966\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    969\u001b[0m         \u001b[1;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'list\\'> containing values of types {\"<class \\'int\\'>\"})'}), (<class 'list'> containing values of types {\"<class 'numpy.int32'>\"})"
     ]
    }
   ],
   "source": [
    "# y_train = list(y_train)\n",
    "\n",
    "# new_model.fit(training_sequences, y_train, epochs=5, batch_size=256,\n",
    "#               validation_data=(testing_sequences, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(training_sequences))\n",
    "print(type(y_test))\n",
    "print(type(y_train))\n",
    "print(type(testing_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive', 'positive', 'positive', 'negative', 'positive']\n",
      "[1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:5])\n",
    "print(y_train[:5])\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
